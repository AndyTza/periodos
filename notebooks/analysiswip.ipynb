{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "Author: Anastasios Tzanidakis\n",
    "\n",
    "In this notebook we report the analysis of PLasTiCC light curves (RRL and EB's) to determine the optimal configuration for Rubuin light curves. Specifically, here are the questions we're trying to understand and optimize:\n",
    "- What version of LSP should we use: `MultiBand` or `SingleBand`\n",
    "    - What LSP algorithm should we use: `Fast` or `Floating Mean/generalized`\n",
    "    - What fourier/base component maximizes the correctly identified periods?\n",
    "    \n",
    "\n",
    "- Should we use a pre-determined frequency grid, automatic frequency grid, or zooming-peak approach\n",
    "    - Pre-determined frequency bin\n",
    "    - Automatic frequency grid based on light curve duration, oversampling, and nyquist correction\n",
    "    - Two stage frequency search grid: [highlighted here](https://jakevdp.github.io/blog/2015/06/13/lomb-scargle-in-python/#:~:text=a%20built%2Din%20two%2Dstage%20grid%2Dsearch%20that%20accurately%20determines%20the%20best%20period%20in%20a%20specified%20range)\n",
    "\n",
    "- How long do these algorithms take in each configuration\n",
    "    - Timing in bins of number of total observations\n",
    "    - Timing in bins of number of base components/Fourier terms \n",
    "    - Timing in bins frequency grid approach\n",
    "   \n",
    "   \n",
    "**Extra Analysis**/future TODO:\n",
    "- What is the **minimum** number of observatiosn we need per light curve in order to recover the correct period?\n",
    "- After $\\mathcal{\\tau}$ years of the survey (PlasTiCC maximum is 3 years; supposed Rubin DR3) - how **many** correctly identified periods would we find?\n",
    "- Should the light curve moment also capture more information from the power spectrum (i.e TOP N peaks?). How many more correctly identified periodicities would be enough?\n",
    "- Using the Rubin `Opsims` cadence, can there be an optimized pre-determined frequency window that maximizes period finding while minimizing computation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Metrics & Setp-up\n",
    "\n",
    "\n",
    "\n",
    "### PlasTiCC Light Curves & Sample\n",
    "--- \n",
    "\n",
    "For this analysis, we will make a few assumptions about the light curves under investigation: \n",
    "- Consider a sample of only RR Lyrae (RRL) and Eclipsing Binaries (EB)\n",
    "- Investigate light curves with a duration (T) less than 365 days\n",
    "- To mimic the effects of forced-photometry, we will include in our analysis both `detection==0, 1` (both detections & non-detections) in the PlasTiCC light curves\n",
    "- We set a minimum number of observations per light curve under investigation to be $N_{min}$=10\n",
    "\n",
    "\n",
    "### Period Metric\n",
    "--- \n",
    "We would like to define some success metric for the correctly identified periods within some margin of error. For my metric, I will estimate a simple percentage error:\n",
    "`\n",
    "$$\\begin{equation} Err = \\frac{|p_{inj}-p_{rec}|}{p_{inj}}\\end{equation}$$\n",
    "\n",
    "where $p_{inj}$ is the injected true period of the light curve, while the $p_{rec}$ is the recovered period from the Lomb-Scargle Periodogram. We note that for this analysis we will assume that the **correct period corresponds to the maximum power**, without considering other harmonics that might be caused by the survey cadence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import ascii\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "from astropy.time import Time\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from gatspy import periodic, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from astropy.table import Table\n",
    "from gatspy import datasets, periodic\n",
    "import gatspy\n",
    "import scipy.stats as sci_stat\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams['savefig.dpi'] = 250\n",
    "rcParams['font.size'] = 20\n",
    "\n",
    "global data_path\n",
    "data_path = '../data/plasticc/data/'\n",
    "\n",
    "# Caution, be careful when ignoring warnings!\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    \"\"\"Not reccomended, but for the moment supress warnings!\"\"\"\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add entire PlasTiCC stream?!\n",
    "data = pd.read_csv(data_path + \"plasticc_test_lightcurves_11.csv.gz\",\n",
    "                  compression='gzip',\n",
    "                  error_bad_lines=False)\n",
    "\n",
    "meta_info = ascii.read(data_path + \"plasticc_train_metadata.csv\") # ascii meta since it's smaller\n",
    "meta_theta_EB = ascii.read(data_path + 'plasticc_modelpar/' + 'plasticc_modelpar_016_EB.csv')\n",
    "meta_theta_RRL = ascii.read(data_path + 'plasticc_modelpar/' + 'plasticc_modelpar_092_RRL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some helper functions for the analysis\n",
    "\n",
    "def generate_lc(obj_id, band='all', data_table=data, det='all', dt_cut=365):\n",
    "    \"\"\"Unpack and return PlastiCC data in numpy array format.\n",
    "\n",
    "    Paremters\n",
    "    ---------\n",
    "    obj_id: Object ID\n",
    "    band: Photometric bandpass filter. 'all' includes ugrizy, or 'ugrizy'\n",
    "    data_table: Pandas data table containing the light curves\n",
    "    det: Detection from the image subtraction algorithm. ==1 detection, ==0 not detection (i.e upper limit) or 'all': uses both 0 & 1\n",
    "    dt_cut: Light curve duration cut in days (default 365 days)\n",
    "    Returns\n",
    "    -------\n",
    "    mjd, magnitude, magnitude_error, filter (if band=='all')\n",
    "    \"\"\"\n",
    "\n",
    "    if det==0 or det==1:\n",
    "        data_table_mod = data_table[data_table['detected_bool']==det]\n",
    "    elif det=='all':\n",
    "        data_table_mod = data_table # select both\n",
    "\n",
    "    # Select light curve based on the ID\n",
    "    lc = data_table_mod[data_table_mod['object_id']==obj_id]\n",
    "\n",
    "    lsst_bands = list('ugrizy') # lsst photomeric bands\n",
    "\n",
    "    lc_array = lc.to_numpy()\n",
    "\n",
    "    # Capture empty light curve\n",
    "    assert len(lc_array[:,1])>0, (\"Sorry, it seems like your obj_id query was wrong!\")\n",
    "\n",
    "    mjd, flux, flux_err = lc_array[:,1], lc_array[:,3], lc_array[:,4]\n",
    "    flt = lc_array[:,2].astype(int).astype(str)\n",
    "\n",
    "    for j in range(6):\n",
    "        flt[flt==str(j)] = lsst_bands[j]\n",
    "\n",
    "    # Baseline cut\n",
    "    baseline = mjd-mjd[0] # calculate baseline\n",
    "    mjd, flux, flux_err, flt = mjd[baseline<=dt_cut], flux[baseline<=dt_cut], flux_err[baseline<=dt_cut], flt[baseline<=dt_cut]\n",
    "\n",
    "    if band=='all':\n",
    "        return mjd, flux, flux_err, flt\n",
    "    else:\n",
    "        return mjd[flt==band], flux[flt==band], flux_err[flt==band], flt[flt==band]\n",
    "\n",
    "def generate_toi_table(data, meta_info, meta_theta_EB, meta_theta_RRL):\n",
    "    \"\"\"\n",
    "    Generate table that contains the light curve ID and transient type given a number of observations cut.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    data: Head data table that contains photometry\n",
    "    meta_info: Table that contains the meta-data (i.e classification name)\n",
    "    meta_theta_<TYPE>: Table that contains metadata information (i.e Period)\n",
    "    nthresh (int): Minimum number of observations in each band must contain\n",
    "    \"\"\"\n",
    "    id_av_rrl, id_av_eb = [], []\n",
    "\n",
    "    for uid in tqdm(np.unique(data['object_id'])):\n",
    "        ww = np.where(meta_theta_EB['object_id'] == uid)\n",
    "        if np.shape(ww)[-1]==1:\n",
    "            id_av_eb.append(uid)\n",
    "\n",
    "    for uid in tqdm(np.unique(data['object_id'])):\n",
    "        ww = np.where(meta_theta_RRL['object_id'] == uid)\n",
    "        if np.shape(ww)[-1]==1:\n",
    "            id_av_rrl.append(uid)\n",
    "\n",
    "    id_av_rrl, id_av_eb = np.array(id_av_rrl), np.array(id_av_eb)\n",
    "\n",
    "    _id1 = np.array(['rrl' for _ in range(len(id_av_rrl))])\n",
    "    _id2 = np.array(['eb' for _ in range(len(id_av_eb))])\n",
    "\n",
    "    # All ID's and & ID tags\n",
    "    all_id = np.concatenate([id_av_rrl, id_av_eb])\n",
    "    _id_all = np.concatenate([_id1, _id2])\n",
    "            \n",
    "    # Final TOI table\n",
    "    toi_table = Table([all_id, _id_all], names=('obj_id', 'type'))\n",
    "\n",
    "    return toi_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345996/345996 [00:14<00:00, 23570.68it/s]\n",
      "100%|██████████| 345996/345996 [00:24<00:00, 13974.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fetch the Object_id of all the targets of interest (toi)\n",
    "toi_table = generate_toi_table(data, meta_info, meta_theta_EB, meta_theta_RRL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some additional helper functions for metadata handiling and processing\n",
    "def fetch_meta_info(lc_id, lc_type):\n",
    "    \"\"\"Fetch metadata for transient type.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    lc_id: Light curve ID\n",
    "    lc_type: classification type (i.e rrl, eb)\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    meta_<type>_table: Table that contains metadata (i.e period and other physical properties)\n",
    "    \"\"\"\n",
    "    if lc_type=='rrl':\n",
    "        # crossmatch to approprirate table\n",
    "        xm_ = np.where(meta_theta_RRL['object_id']==lc_id)\n",
    "        return meta_theta_RRL[xm_]\n",
    "    elif lc_type=='eb':\n",
    "        # crossmatch to approprirate table\n",
    "        xm_ = np.where(meta_theta_EB['object_id']==lc_id)\n",
    "        return meta_theta_EB[xm_]\n",
    "\n",
    "# Write a function that will generate N random from each class (equal)\n",
    "def draw_rand_trans(table, N, class_type='rrl'):\n",
    "    \"\"\"Draw N random object_id's from the specific class (with no repeats)\n",
    "       Note: It will not draw the same transiennt\n",
    "    \"\"\"\n",
    "    # isolate each unique class\n",
    "    req_tab = table[table['type']==class_type]\n",
    "\n",
    "    # Random number generator w/o repeat\n",
    "    rng = np.random.default_rng()\n",
    "    rn = rng.choice(len(req_tab), size=N, replace=False)\n",
    "\n",
    "    return req_tab[rn]\n",
    "\n",
    "def percent_error(true, obs):\n",
    "    \"\"\"Calculate the absolute percent error.\"\"\"\n",
    "    return abs(true-obs)/true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1 - Adressing the Single Band LSP\n",
    "We begin our analysis on single band photometric LSP analysis. Here we will be adressing a few questions: \n",
    "\n",
    "- For each photometric filter, what configuration minimizes the percent error?\n",
    "    - Which method is better, `Fast` or `Floating Mean`\n",
    "    - What frequency grid to choose?\n",
    "\n",
    "- Timing analysis: \n",
    "    - Timing per number of total observations (likely in bins=10)\n",
    "    - Timing per number of components (only applies to Floating Mean)\n",
    "    - Timing per grid search\n",
    "    \n",
    "    \n",
    "    \n",
    "**Internal Notes/Figures**:\n",
    "- Start with with `Fast`:\n",
    "    - What frequency grid and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:09<00:00, 72.15it/s]\n",
      "100%|██████████| 5000/5000 [01:10<00:00, 70.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate a sample of RRL & EB's with 10 total observations per photometric band\n",
    "rrl_table = draw_rand_trans(toi_table, 5_000, 'rrl')\n",
    "eb_table = draw_rand_trans(toi_table, 5_000, 'eb')\n",
    "\n",
    "def band_cut(dat_table, band='r', nthresh=10, dt_cut=365):\n",
    "    \"\"\"Return object_id to sources on a specified photometric filter given some threshold detection cut.\"\"\"\n",
    "    \n",
    "    idi = []  \n",
    "    for _id in tqdm(dat_table['obj_id']):\n",
    "        # Fetch light curve info\n",
    "        lc = generate_lc(_id, band=band, det='all', dt_cut=dt_cut)\n",
    "        if len(lc[0])>=nthresh:\n",
    "            idi.append(_id)\n",
    "    return np.array(idi)\n",
    "\n",
    "rrl_u, eb_u = band_cut(rrl_table, band='u', nthresh=10), band_cut(eb_table, band='u', nthresh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:27<00:00, 71.51it/s]\n"
     ]
    }
   ],
   "source": [
    "len(rrl_u), len(eb_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
